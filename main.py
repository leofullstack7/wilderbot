# ============================
#  WilderBot API - VERSIÃ“N CORREGIDA
#  Correcciones:
#  1. Bot se identifica como ASISTENTE de Wilder (no como Wilder)
#  2. Solo saluda UNA VEZ al inicio
#  3. Respeta estrictamente informaciÃ³n RAG (no inventa)
# ============================

from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
from pinecone import Pinecone
from typing import Optional, List, Dict, Any, Tuple
from google.cloud.firestore_v1 import Increment

import json
import os
from dotenv import load_dotenv
import re
import math
import time

from api.ingest import router as ingest_router
from fastapi.middleware.cors import CORSMiddleware

import firebase_admin
from firebase_admin import credentials, firestore

# =========================================================
#  Config
# =========================================================

load_dotenv()

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["POST", "GET", "OPTIONS"],
    allow_headers=["*"],
)

app.include_router(ingest_router)

OPENAI_API_KEY   = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL     = os.getenv("OPENAI_MODEL", "gpt-4o")
EMBEDDING_MODEL  = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX   = os.getenv("PINECONE_INDEX", "wilder-frases")
GOOGLE_CREDS     = os.getenv("GOOGLE_APPLICATION_CREDENTIALS") or "/etc/secrets/firebase.json"
OPENAI_MODEL_SUMMARY = os.getenv("OPENAI_MODEL_SUMMARY", "gpt-4o-mini")

BOT_INTRO_TEXT = os.getenv(
    "BOT_INTRO_TEXT",
    "Â¡Hola! Soy el asistente de Wilder Escobar. Estoy aquÃ­ para escuchar y canalizar tus "
    "problemas, propuestas o reconocimientos. Â¿QuÃ© te gustarÃ­a contarme hoy?"
)

PRIVACY_REPLY = (
    "Entiendo perfectamente que quieras proteger tu informaciÃ³n personal. "
    "Queremos que sepas que tus datos estÃ¡n completamente seguros con nosotros. "
    "Cumplimos con todas las normativas de protecciÃ³n de datos y solo usamos tu informaciÃ³n "
    "para escalar tu propuesta y ayudar a que pueda hacerse realidad."
)

# === Clientes ===
client = OpenAI(api_key=OPENAI_API_KEY)
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(PINECONE_INDEX)

# === Firestore Admin ===
try:
    firebase_admin.get_app()
except ValueError:
    cred = credentials.Certificate(GOOGLE_CREDS)
    firebase_admin.initialize_app(cred)

db = firestore.client()

# =========================================================
#  Esquemas
# =========================================================

class Entrada(BaseModel):
    mensaje: str
    usuario: Optional[str] = None
    chat_id: Optional[str] = None
    canal: Optional[str] = None
    faq_origen: Optional[str] = None
    nombre: Optional[str] = None
    celular: Optional[str] = None

class ClasificarIn(BaseModel):
    chat_id: str
    contabilizar: Optional[bool] = None

@app.get("/health")
async def health():
    return {"status": "ok"}

# =========================================================
#  Utils
# =========================================================

def _normalize_text(t: str) -> str:
    t = t.lower()
    t = (t.replace("Ã¡","a").replace("Ã©","e").replace("Ã­","i")
           .replace("Ã³","o").replace("Ãº","u").replace("Ã¼","u"))
    t = re.sub(r"[^a-zÃ±0-9\s]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

DISCOURSE_START_WORDS = {
    _normalize_text(w) for w in [
        "hola", "holaa", "holaaa", "buenas", "buenos dÃ­as", "saludos",
        "gracias", "ok", "okay", "vale", "listo", "perfecto", "claro", "sÃ­", "si"
    ]
}

def limit_sentences(text: str, max_sentences: int = 3) -> str:
    parts = re.split(r'(?<=[\.\?!])\s+', text.strip())
    out = " ".join([p for p in parts if p][:max_sentences]).strip()
    return out or text

def _titlecase(s: str) -> str:
    return re.sub(r"\s+", " ", s.strip()).title()

def _clean_barrio_fragment(s: str) -> str:
    s = re.split(r"\s+(?:para|por|que|donde|con)\b|[,.;]|$", s, maxsplit=1, flags=re.IGNORECASE)[0]
    return _titlecase(s)

# âœ… CORRECCIÃ“N: Eliminar saludos redundantes
def remove_redundant_greetings(texto: str, historial: List[Dict[str, str]]) -> str:
    """Elimina saludos si ya hubo interacciÃ³n previa."""
    if historial and len(historial) > 0:
        greeting_patterns = [
            r'^Â¡?Hola!?\s*[,.]?\s*',
            r'^Â¡?Holaa!?\s*[,.]?\s*',
            r'^Buenas\s+(tardes|noches|dÃ­as)[,.]?\s*',
            r'^Â¡?QuÃ©\s+tal!?\s*[,.]?\s*',
            r'^Â¡?Saludos!?\s*[,.]?\s*',
        ]
        
        for pattern in greeting_patterns:
            texto = re.sub(pattern, '', texto, flags=re.IGNORECASE)
        
        texto = re.sub(r'^Â¡?Hola,?\s+[A-Za-zÃ¡Ã©Ã­Ã³ÃºÃ±]+[,.]?\s*', '', texto, flags=re.IGNORECASE)
    
    texto = texto.strip()
    
    if not texto or len(texto) < 10:
        return "Claro, dÃ©jame ayudarte con eso."
    
    return texto

# =========================================================
#  BD Helpers
# =========================================================

def upsert_usuario_o_anon(
    chat_id: str,
    nombre: Optional[str],
    telefono: Optional[str],
    canal: Optional[str],
    barrio: Optional[str] = None
) -> str:
    usuario_id = chat_id

    if telefono:
        ref = db.collection("usuarios").document(usuario_id)
        doc = ref.get()
        if not doc.exists:
            ref.set({
                "nombre": nombre or "",
                "telefono": telefono,
                "barrio": barrio or None,
                "fecha_registro": firestore.SERVER_TIMESTAMP,
                "chats": [chat_id],
                "canal": canal or "web",
            })
        else:
            prev = doc.to_dict() or {}
            ref.update({
                "nombre": nombre or prev.get("nombre", ""),
                "telefono": telefono,
                "barrio": barrio or prev.get("barrio"),
                "chats": firestore.ArrayUnion([chat_id]),
                "canal": canal or prev.get("canal", "web"),
            })
    else:
        ref = db.collection("anonimos").document(usuario_id)
        doc = ref.get()
        if not doc.exists:
            ref.set({
                "nombre": nombre or None,
                "fecha_registro": firestore.SERVER_TIMESTAMP,
                "chats": [chat_id],
                "canal": canal or "web",
            })
        else:
            prev = doc.to_dict() or {}
            ref.update({
                "nombre": nombre or prev.get("nombre", None),
                "chats": firestore.ArrayUnion([chat_id]),
                "canal": canal or prev.get("canal", "web"),
            })
    return usuario_id

def ensure_conversacion(chat_id: str, usuario_id: str, faq_origen: Optional[str], canal: Optional[str]):
    conv_ref = db.collection("conversaciones").document(chat_id)
    if not conv_ref.get().exists:
        conv_ref.set({
            "usuario_id": usuario_id,
            "faq_origen": faq_origen or None,
            "canal": canal or "web",
            "categoria_general": [],
            "titulo_propuesta": [],
            "mensajes": [],
            "fecha_inicio": firestore.SERVER_TIMESTAMP,
            "ultima_fecha": firestore.SERVER_TIMESTAMP,
            "tono_detectado": None,
            "last_topic_vec": None,
            "last_topic_summary": None,
            "awaiting_topic_confirm": False,
            "candidate_new_topic_summary": None,
            "candidate_new_topic_vec": None,
            "topics_history": [],
            "argument_requested": False,
            "argument_collected": False,
            "proposal_requested": False,
            "proposal_collected": False,
            "current_proposal": None,
            "contact_intent": None,
            "contact_requested": False,
            "contact_collected": False,
            "contact_refused": False,
            "contact_info": {"nombre": None, "barrio": None, "telefono": None},
            "project_location": None,
            "location_note_sent": False,
        })
    else:
        if canal:
            conv_ref.update({"ultima_fecha": firestore.SERVER_TIMESTAMP, "canal": canal})
        else:
            conv_ref.update({"ultima_fecha": firestore.SERVER_TIMESTAMP})
    return conv_ref

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESUMEN COMPLETO ESTRUCTURADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_detailed_summary(conv_data: dict, mensajes: List[Dict[str, str]]) -> dict:
    """
    Genera un resumen estructurado completo para el botÃ³n "Ver mÃ¡s".
    
    Devuelve un objeto con:
    - tema_principal: str
    - consultas: List[str]  (si hubo consultas)
    - propuesta: str (si hay)
    - argumento: str (si hay)
    - ubicacion: str (si hay)
    - contacto: dict (datos recopilados)
    - estado: str (fase actual)
    - historial_resumido: List[dict] (Ãºltimos 5 intercambios)
    """
    
    summary = {
        "tema_principal": "",
        "consultas": [],
        "propuesta": None,
        "argumento": None,
        "ubicacion": None,
        "contacto": {
            "nombre": None,
            "barrio": None,
            "telefono": None
        },
        "estado": "iniciado",
        "historial_resumido": []
    }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. TEMA PRINCIPAL
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    categorias = conv_data.get("categoria_general", [])
    titulos = conv_data.get("titulo_propuesta", [])
    
    if titulos:
        summary["tema_principal"] = titulos[-1]  # Ãšltimo tÃ­tulo
    elif categorias:
        summary["tema_principal"] = categorias[-1]
    else:
        summary["tema_principal"] = "ConversaciÃ³n sin clasificar"
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. CONSULTAS (si la categorÃ­a incluye "Consulta")
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "Consulta" in categorias:
        # Extraer tÃ­tulos de consultas
        for titulo in titulos:
            if any(kw in _normalize_text(titulo) for kw in ["ley", "proyecto", "apoyo", "posicion", "posiciÃ³n"]):
                summary["consultas"].append(titulo)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. PROPUESTA
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    propuesta = conv_data.get("current_proposal")
    if propuesta:
        # Limpiar y limitar a 120 caracteres
        summary["propuesta"] = propuesta[:120] + ("..." if len(propuesta) > 120 else "")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. ARGUMENTO (buscar en los mensajes del usuario)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if conv_data.get("argument_collected"):
        # Buscar el mensaje con el argumento
        for i, m in enumerate(mensajes):
            if m.get("role") == "user":
                content = m.get("content", "")
                # Si tiene palabras clave de argumento y es largo
                if has_argument_text(content) and len(content) > 30:
                    summary["argumento"] = content[:120] + ("..." if len(content) > 120 else "")
                    break
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. UBICACIÃ“N
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    project_location = conv_data.get("project_location")
    if project_location:
        summary["ubicacion"] = project_location
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 6. CONTACTO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    contact_info = conv_data.get("contact_info", {})
    if contact_info:
        summary["contacto"] = {
            "nombre": contact_info.get("nombre"),
            "barrio": contact_info.get("barrio"),
            "telefono": contact_info.get("telefono")
        }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 7. ESTADO (fase actual del flujo)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if conv_data.get("contact_collected"):
        summary["estado"] = "completado"
    elif conv_data.get("contact_requested"):
        summary["estado"] = "esperando_contacto"
    elif conv_data.get("argument_collected"):
        summary["estado"] = "argumento_recibido"
    elif conv_data.get("proposal_collected"):
        summary["estado"] = "propuesta_recibida"
    elif "Consulta" in categorias:
        summary["estado"] = "consulta_respondida"
    else:
        summary["estado"] = "iniciado"
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 8. HISTORIAL RESUMIDO (Ãºltimos 5 intercambios)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Tomar Ãºltimos 10 mensajes (5 intercambios usuario-bot)
    recent = mensajes[-10:] if len(mensajes) > 10 else mensajes
    
    for m in recent:
        role = m.get("role")
        content = m.get("content", "")
        
        if role == "user":
            role_display = "Usuario"
        elif role == "assistant":
            role_display = "Asistente"
        else:
            continue
        
        # Limitar a 100 caracteres
        content_short = content[:100] + ("..." if len(content) > 100 else "")
        
        summary["historial_resumido"].append({
            "rol": role_display,
            "mensaje": content_short
        })
    
    return summary


def append_mensajes(conv_ref, nuevos: List[Dict[str, Any]]):
    snap = conv_ref.get()
    data = snap.to_dict() or {}
    arr = data.get("mensajes", [])
    arr.extend(nuevos)
    conv_ref.update({"mensajes": arr, "ultima_fecha": firestore.SERVER_TIMESTAMP})

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RESUMEN PRELIMINAR (100 chars para vista rÃ¡pida)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    try:
        resumen = summarize_conversation_brief(arr, max_chars=100)
        conv_ref.update({"resumen": resumen})
    except:
        pass
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RESUMEN COMPLETO (estructura detallada para "Ver mÃ¡s")
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    try:
        resumen_completo = build_detailed_summary(data, arr)
        conv_ref.update({"resumen_completo": resumen_completo})
    except Exception as e:
        print(f"[WARN] Resumen completo fallÃ³: {e}")
    
    try:
        update_conversation_summary(conv_ref)
    except:
        pass

def load_historial_para_prompt(conv_ref) -> List[Dict[str, str]]:
    snap = conv_ref.get()
    if snap.exists:
        data = snap.to_dict() or {}
        msgs = data.get("mensajes", [])
        out = []
        for m in msgs[-8:]:
            role = m.get("role")
            content = m.get("content", "")
            if role in ("user", "assistant") and content:
                out.append({"role": role, "content": content})
        return out
    return []

def update_conversation_summary(conv_ref, force: bool = False):
    snap = conv_ref.get()
    data = snap.to_dict() or {}
    
    msg_count = int(data.get("messages_since_summary", 0)) + 1
    
    if msg_count < 4 and not force:
        conv_ref.update({"messages_since_summary": msg_count})
        return
    
    all_messages = data.get("mensajes", [])
    
    if len(all_messages) < 4:
        return
    
    recent = all_messages[-12:]
    transcript = []
    for m in recent:
        role = "U" if m["role"] == "user" else "B"
        content = (m.get("content", "") or "")[:180]
        transcript.append(f"{role}: {content}")
    
    transcript_text = "\n".join(transcript)
    
    sys = (
        "Resume en 140 caracteres: tema, propuesta (si hay), fase.\n"
        "Sin nombres ni telÃ©fonos."
    )
    
    try:
        response = client.chat.completions.create(
            model=OPENAI_MODEL_SUMMARY,
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": transcript_text}
            ],
            temperature=0.2,
            max_tokens=50,
            timeout=3
        )
        
        summary = response.choices[0].message.content.strip()[:140]
        
        conv_ref.update({
            "conversacion_resumida": summary,
            "messages_since_summary": 0
        })
        
    except:
        pass

def summarize_conversation_brief(mensajes: List[Dict[str, str]], max_chars: int = 100) -> str:
    parts = []
    for m in mensajes[-40:]:
        role = m.get("role")
        content = (m.get("content") or "").strip()
        if not content:
            continue
        content = re.sub(r"\+?\d[\d\s\-]{6,}", "[nÃºmero]", content)
        tag = "C" if role == "user" else "B"
        parts.append(f"{tag}: {content}")
    transcript = "\n".join(parts) if parts else ""

    try:
        out = client.chat.completions.create(
            model=OPENAI_MODEL_SUMMARY,
            messages=[
                {"role": "system", "content": "Resume en 100 chars."},
                {"role": "user", "content": transcript}
            ],
            temperature=0.2,
            max_tokens=60,
        ).choices[0].message.content
    except:
        out = (mensajes[0].get("content") if mensajes else "")[:max_chars]

    return out[:max_chars]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTEXTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConversationContext:
    def __init__(self, conv_data: dict, mensaje: str):
        self.mensaje = mensaje
        self.mensaje_norm = _normalize_text(mensaje)
        
        self.in_proposal_flow = bool(
            conv_data.get("proposal_collected") or
            conv_data.get("proposal_requested") or
            conv_data.get("argument_requested") or
            conv_data.get("contact_intent") == "propuesta"
        )
        
        self.contact_requested = bool(conv_data.get("contact_requested"))
        self.contact_collected = bool(conv_data.get("contact_collected"))
        self.contact_refused = bool(conv_data.get("contact_refused"))
        self.argument_requested = bool(conv_data.get("argument_requested"))
        self.argument_collected = bool(conv_data.get("argument_collected"))
        self.proposal_collected = bool(conv_data.get("proposal_collected"))
        
        self.contact_info = conv_data.get("contact_info") or {}
        self.project_location = conv_data.get("project_location")
        self.current_proposal = conv_data.get("current_proposal")
        self.resumen = conv_data.get("conversacion_resumida", "")
        
        mensajes = conv_data.get("mensajes", [])
        self.historial = [
            {"role": m["role"], "content": m["content"]}
            for m in mensajes[-8:]
            if m.get("role") in ("user", "assistant") and m.get("content")
        ]
        
        self.has_reference = self._detect_reference()
    
    def _detect_reference(self) -> bool:
        referencias = [
            "eso", "esa", "ese", "lo que", "la que", "el que",
            "sobre eso", "de eso", "aquello", "aquel",
            "el primero", "el segundo", "esa ley", "ese proyecto"
        ]
        return any(ref in self.mensaje_norm for ref in referencias)
    
    def get_missing_contact_fields(self) -> List[str]:
        missing = []
        if not self.contact_info.get("nombre"):
            missing.append("nombre")
        if not self.contact_info.get("barrio"):
            missing.append("barrio")
        if not self.contact_info.get("telefono"):
            missing.append("celular")
        return missing

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DETECCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_plain_greeting(text: str) -> bool:
    if not text:
        return False
    t = _normalize_text(text)
    kws = ("hola","holaa","buenas","buenos dias","como estas","que mas","saludos")
    short = len(t) <= 40
    has_kw = any(k in t for k in kws)
    topicish = any(w in t for w in (
        "arregl","propuesta","proponer","hueco","parque","colegio",
        "salud","seguridad","ayuda","necesito","quiero"
    ))
    return short and has_kw and not topicish

def detect_contact_refusal(text: str) -> bool:
    t = _normalize_text(text)
    return any(p in t for p in [
        "no me gusta dar mis datos",
        "no quiero compartir mis datos",
        "no doy mi celular"
    ])

def is_proposal_denial(text: str) -> bool:
    t = _normalize_text(text)
    pats = [
        r'\b(aun|aÃºn|todavia)\s+no\b.*\b(propuest|idea)',
        r'\b(no\s+tengo|no\s+he\s+hecho)\b.*\b(propuest|idea)',
        r'\b(olvidalo|mejor\s+no|mas\s+tarde)\b'
    ]
    return any(re.search(p, t) for p in pats)

def is_proposal_intent_heuristic(text: str) -> bool:
    t = _normalize_text(text)
    kw = ["propongo", "propuesta", "sugerencia", "mi idea", "quiero proponer"]
    return any(k in t for k in kw)

def looks_like_proposal_content(text: str) -> bool:
    """
    Detecta si el texto contiene una propuesta CON CONTENIDO REAL.
    
    NO es propuesta si:
    - Es negaciÃ³n
    - Es solo intenciÃ³n ("quiero proponer")
    - No tiene verbos de acciÃ³n ni sustantivos especÃ­ficos
    """
    if is_proposal_denial(text):
        return False
    
    t = _normalize_text(text)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Rechazar intenciÃ³n pura sin contenido
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    intencion_pura = re.match(
        r'^\s*(?:quiero|quisiera|me gustaria)\s+(?:proponer|hacer\s+una\s+propuesta)\s*$',
        t
    )
    if intencion_pura:
        return False
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Debe tener VERBO DE ACCIÃ“N + OBJETO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tiene_verbo = bool(re.search(
        r'\b(arregl|mejor|constru|instal|crear|paviment|ilumin|repar|pint|adecu|seÃƒÂ±aliz)\w*',
        t
    ))
    
    tiene_objeto = bool(re.search(
        r'\b(alumbrado|luminaria|parque|semaforo|cancha|via|calle|anden|acera|juegos|polideportivo|hospital|colegio|puesto|centro)\b',
        t
    ))
    
    tiene_ubicacion = bool(re.search(
        r'\b(barrio|sector|comuna|vereda|en\s+[A-Z])\b',
        text  # Original sin normalizar para detectar mayÃºsculas
    ))
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Criterios de aceptaciÃ³n
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # Caso 1: Verbo + Objeto (suficiente)
    if tiene_verbo and tiene_objeto:
        return True
    
    # Caso 2: Verbo + UbicaciÃ³n + longitud razonable
    if tiene_verbo and tiene_ubicacion and len(t) >= 15:
        return True
    
    # Caso 3: Objeto + UbicaciÃ³n + longitud razonable
    if tiene_objeto and tiene_ubicacion and len(t) >= 15:
        return True
    
    # Caso 4: Muy largo Y tiene al menos algo relevante
    if len(t) >= 40 and (tiene_verbo or tiene_objeto):
        return True
    
    # Rechazar todo lo demÃ¡s
    return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTRACCIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_user_name(text: str) -> Optional[str]:
    m = re.search(r'\b(?:soy|me llamo|mi nombre es)\s+([A-Za-zÃ¡Ã©Ã­Ã³ÃºÃ± ]{2,40})', text, flags=re.IGNORECASE)
    if m:
        nombre = m.group(1).strip(" .,")
        return nombre if _normalize_text(nombre) not in DISCOURSE_START_WORDS else None
    return None

def extract_phone(text: str) -> Optional[str]:
    m = re.search(r'(\+?\d[\d\s\-]{7,16}\d)', text)
    if not m:
        return None
    tel = re.sub(r'\D', '', m.group(1))
    tel = re.sub(r'^(?:00)?57', '', tel)
    return tel if 8 <= len(tel) <= 12 else None

def extract_user_barrio(text: str) -> Optional[str]:
    m = re.search(r'\b(?:vivo|resido)\s+en\s+(?:el\s+)?(?:barrio\s+)?([A-Za-zÃ¡Ã©Ã­Ã³ÃºÃ±0-9 \-]{2,50})', text, flags=re.IGNORECASE)
    if m:
        return _clean_barrio_fragment(m.group(1))
    return None

def extract_project_location(text: str) -> Optional[str]:
    m = re.search(r'\ben\s+el\s+barrio\s+([A-Za-zÃ¡Ã©Ã­Ã³ÃºÃ±0-9 \-]{2,50})', text, flags=re.IGNORECASE)
    if m:
        return _clean_barrio_fragment(m.group(1))
    return None

def extract_proposal_text(text: str) -> str:
    t = text.strip()
    t = re.sub(r'^\s*(?:hola|buenas)[,!\s\-]*', '', t, flags=re.IGNORECASE)
    return limit_sentences(t, 2)

def llm_extract_contact_info(text: str) -> Dict[str, Optional[str]]:
    sys = "Extrae: nombre, barrio, telefono. JSON."
    usr = f"Mensaje: {text}"
    
    try:
        out = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "system", "content": sys}, {"role": "user", "content": usr}],
            temperature=0.0,
            max_tokens=150
        ).choices[0].message.content.strip()
        
        return json.loads(out)
    except:
        return {"nombre": None, "barrio": None, "telefono": None}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CAPAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def layer1_deterministic_response(ctx: ConversationContext, conv_data: dict) -> Optional[str]:
    if not ctx.historial and is_plain_greeting(ctx.mensaje):
        print("[LAYER1] âœ“ Saludo inicial")
        return BOT_INTRO_TEXT
    
    if ctx.contact_requested and not ctx.contact_collected:
        if detect_contact_refusal(ctx.mensaje):
            refusal_count = int(conv_data.get("contact_refusal_count", 0))
            if refusal_count == 0:
                return PRIVACY_REPLY + " Â¿Me compartes tus datos?"
            else:
                return "Entiendo tu decisiÃ³n. Â¡Que tengas buen dÃ­a!"
    
    if is_proposal_denial(ctx.mensaje):
        return "Perfecto. Cuando la tengas, cuÃ©ntamela."
    
    return None

def layer2_extract_contact_data(ctx: ConversationContext) -> Dict[str, Optional[str]]:
    name_regex = extract_user_name(ctx.mensaje)
    phone_regex = extract_phone(ctx.mensaje)
    barrio_regex = extract_user_barrio(ctx.mensaje)
    
    if name_regex and phone_regex and barrio_regex:
        return {"nombre": name_regex, "telefono": phone_regex, "barrio": barrio_regex}
    
    if ctx.contact_requested:
        if not phone_regex:
            m = re.search(r'\b(\d{10})\b', ctx.mensaje)
            if m:
                phone_regex = m.group(1)
    
    result = {}
    if name_regex: result["nombre"] = name_regex
    if phone_regex: result["telefono"] = phone_regex
    if barrio_regex: result["barrio"] = barrio_regex
    return result

def layer3_classify_with_context(ctx: ConversationContext) -> Dict[str, Any]:
    if ctx.in_proposal_flow:
        return {"tipo": "propuesta", "confianza": "alta"}
    
    if is_proposal_intent_heuristic(ctx.mensaje):
        return {"tipo": "propuesta", "confianza": "alta"}
    
    if "?" in ctx.mensaje:
        return {"tipo": "consulta", "confianza": "alta"}
    
    return {"tipo": "consulta", "confianza": "media"}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RAG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def rag_search(query: str, top_k: int = 5):
    emb = client.embeddings.create(model=EMBEDDING_MODEL, input=query).data[0].embedding
    res = index.query(vector=emb, top_k=top_k, include_metadata=True)
    hits = []
    for m in res.matches:
        hits.append({
            "id": m.id,
            "texto": (m.metadata or {}).get("texto", ""),
            "score": float(m.score)
        })
    return hits

# âœ… CORRECCIÃ“N: ReformulaciÃ³n mejorada
def reformulate_query_with_context(
    current_query: str, 
    conversation_history: List[Dict[str, str]],
    max_history: int = 6
) -> str:
    """Reformula manteniendo tema especÃ­fico."""
    
    if len(current_query.split()) > 8:
        return current_query
    
    recent = conversation_history[-max_history:] if conversation_history else []
    
    if not recent:
        return current_query
    
    # Extraer tema del Ãºltimo bot
    ultimo_bot = ""
    tema_especifico = ""
    
    for msg in reversed(recent):
        if msg["role"] == "assistant":
            ultimo_bot = msg.get("content", "")
            
            ley_match = re.search(r'Ley\s+(\d+)', ultimo_bot, re.IGNORECASE)
            if ley_match:
                tema_especifico = f"Ley {ley_match.group(1)}"
                break
    
    referencias_vagas = ["ella", "eso", "esa", "sobre eso"]
    if tema_especifico and any(ref in current_query.lower() for ref in referencias_vagas):
        reformulated = f"{tema_especifico} detalles"
        print(f"[QUERY] Reformulada: '{reformulated}'")
        return reformulated
    
    return current_query

# âœ… CORRECCIÃ“N: Validar relevancia RAG
# âœ… CORRECCIÃ“N: Validar relevancia RAG (umbral ajustado)
def validate_rag_relevance(rag_hits: List[Dict]) -> bool:
    """
    Valida si hay al menos UN hit con score razonable.
    Umbral bajado a 0.5 para mayor flexibilidad.
    """
    if not rag_hits:
        print("[RAG] âš ï¸  No hay hits")
        return False
    
    # Buscar al menos un hit con score > 0.5
    best_score = max((hit.get("score", 0) for hit in rag_hits), default=0)
    
    if best_score >= 0.5:
        print(f"[RAG] âœ… Mejor score: {best_score:.3f}")
        return True
    else:
        print(f"[RAG] âš ï¸ Score muy bajo: {best_score:.3f}")
        # Aceptar de todos modos si hay al menos 3 hits
        if len(rag_hits) >= 3:
            print("[RAG] âš ï¸ Aceptando por cantidad de hits")
            return True
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HELPERS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_contact_request(missing: List[str]) -> str:
    etiquetas = {"nombre": "tu nombre", "barrio": "tu barrio", "celular": "celular"}
    pedir = [etiquetas[m] for m in missing if m in etiquetas]
    frase = pedir[0] if len(pedir) == 1 else (", ".join(pedir[:-1]) + " y " + pedir[-1])
    return f"Â¿Me compartes {frase}?"

def build_project_location_request() -> str:
    """Pide el barrio del proyecto especÃ­ficamente."""
    return "Para ubicar el caso en el mapa: Â¿en quÃ© barrio serÃ­a exactamente el proyecto?"

def craft_argument_question(name: Optional[str], project_location: Optional[str] = None) -> str:
    saludo = f"{name}, " if name else ""
    return f"{saludo}Â¿Por quÃ© es importante?"

def positive_ack_and_request_argument(name: Optional[str], project_location: Optional[str] = None) -> str:
    return "Excelente idea. Â¿Por quÃ© serÃ­a importante?"

def strip_contact_requests(texto: str) -> str:
    return texto

# âœ… CORRECCIÃ“N CRÃTICA: GeneraciÃ³n con validaciÃ³n RAG
def layer4_generate_response_with_memory(
    ctx: ConversationContext,
    clasificacion: Dict[str, Any],
    rag_hits: List[Dict]
) -> str:
    """GeneraciÃ³n con respeto estricto a RAG."""
    
    contexto_rag = "\n".join([f"- {h['texto']}" for h in rag_hits if h.get("texto")])
    
    # âœ… System prompt corregido
    system_msg = (
        "Eres el ASISTENTE de Wilder Escobar, Representante a la CÃ¡mara.\n\n"
        "REGLAS ESTRICTAS:\n"
        "1. NO te presentes como Wilder, eres su ASISTENTE\n"
        "2. NO saludes si ya hay historial\n"
        "3. Usa SOLO informaciÃ³n del contexto proporcionado\n"
        "4. Si el contexto no tiene la info, di: 'No tengo esa informaciÃ³n especÃ­fica'\n"
        "5. MÃ¡ximo 3 frases\n\n"
    )
    
    if ctx.has_reference and ctx.resumen:
        system_msg += f"CONTEXTO PREVIO: {ctx.resumen}\n"
        system_msg += "MantÃ©n coherencia con ese tema.\n\n"
    
    if clasificacion["tipo"] == "consulta":
        system_msg += (
            "CONSULTA: Usa ÃšNICAMENTE el contexto.\n"
            "NO inventes informaciÃ³n.\n"
            "Si no estÃ¡ en el contexto, dilo claramente.\n"
        )
    
    msgs = [{"role": "system", "content": system_msg}]
    
    if ctx.historial:
        msgs.extend(ctx.historial[-6:])
    
    msgs.append({
        "role": "user",
        "content": (
            f"CONTEXTO VERIFICADO:\n{contexto_rag}\n\n"
            f"PREGUNTA:\n{ctx.mensaje}\n\n"
            f"Responde SOLO con info del contexto."
        )
    })
    
    try:
        completion = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=msgs,
            temperature=0.1,  # âœ… Baja temperatura
            max_tokens=280
        )
        
        texto = completion.choices[0].message.content.strip()
        texto = limit_sentences(texto, 3)
        
        # âœ… Eliminar saludos
        texto = remove_redundant_greetings(texto, ctx.historial)
        
        return texto
        
    except Exception as e:
        return "Disculpa, tuve un problema. Â¿Reformulas?"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINT PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/responder")
async def responder(data: Entrada):
    try:
        chat_id = data.chat_id or f"web_{os.urandom(4).hex()}"
        usuario_id = upsert_usuario_o_anon(chat_id, data.nombre or data.usuario, data.celular, data.canal)
        conv_ref = ensure_conversacion(chat_id, usuario_id, data.faq_origen, data.canal)
        conv_data = conv_ref.get().to_dict() or {}
        
        ctx = ConversationContext(conv_data, data.mensaje)
        
        # CAPA 1
        layer1_response = layer1_deterministic_response(ctx, conv_data)
        if layer1_response:
            if is_proposal_denial(data.mensaje):
                conv_ref.update({
                    "proposal_requested": False,
                    "proposal_collected": False,
                    "argument_requested": False,
                    "argument_collected": False,
                })
            
            append_mensajes(conv_ref, [
                {"role": "user", "content": data.mensaje},
                {"role": "assistant", "content": layer1_response}
            ])
            return {"respuesta": layer1_response, "fuentes": [], "chat_id": chat_id}
        
        # CAPA 2
        extracted_data = layer2_extract_contact_data(ctx)
        
        if extracted_data:
            current_info = ctx.contact_info.copy()
            if extracted_data.get("nombre"):
                current_info["nombre"] = extracted_data["nombre"]
            if extracted_data.get("telefono"):
                current_info["telefono"] = extracted_data["telefono"]
            if extracted_data.get("barrio"):
                current_info["barrio"] = extracted_data["barrio"]
            
            conv_ref.update({"contact_info": current_info})
            
            if current_info.get("telefono"):
                conv_ref.update({"contact_collected": True})
            
            ctx.contact_info = current_info
        
        proj_loc = extract_project_location(data.mensaje)
        if proj_loc:
            conv_ref.update({"project_location": proj_loc})
        
        # CAPA 3
        clasificacion = layer3_classify_with_context(ctx)
        
        # PROPUESTAS (simplificado)
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # FLUJO COMPLETO: PROPUESTAS
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if clasificacion["tipo"] == "propuesta" or ctx.in_proposal_flow:
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # FASE 1: Recopilar la propuesta
            if not ctx.proposal_collected:
                if looks_like_proposal_content(data.mensaje):
                    propuesta_extraida = extract_proposal_text(data.mensaje)
                    
                    # âš ï¸ VALIDACIÃ“N EXTRA: Verificar que la propuesta extraÃ­da no estÃ© vacÃ­a
                    if len(_normalize_text(propuesta_extraida)) < 10:
                        # La propuesta extraÃ­da es muy corta, pedir mÃ¡s detalles
                        conv_ref.update({"proposal_requested": True})
                        texto = "CuÃ©ntame un poco mÃ¡s sobre tu propuesta. Â¿QuÃ© te gustarÃ­a que se hiciera y en quÃ© barrio?"
                        append_mensajes(conv_ref, [
                            {"role": "user", "content": data.mensaje},
                            {"role": "assistant", "content": texto}
                        ])
                        return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
                    
                    # Propuesta vÃ¡lida, guardar y pedir argumento
                    conv_ref.update({
                        "current_proposal": propuesta_extraida,
                        "proposal_collected": True,
                        "proposal_requested": True,
                        "argument_requested": True,
                        "argument_collected": False,
                    })
                    texto = positive_ack_and_request_argument(
                        ctx.contact_info.get("nombre"),
                        ctx.project_location
                    )
                    
                    print(f"[PROPUESTA] âœ… Guardada: '{propuesta_extraida[:50]}...'")
                    print(f"[PROPUESTA] â¡ï¸  Pidiendo argumento")
                    
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
                else:
                    # Pedir la propuesta
                    conv_ref.update({"proposal_requested": True})
                    texto = "Â¡Perfecto! Â¿CuÃ¡l es tu propuesta? CuÃ©ntamela en una o dos frases."
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # FASE 2: Recopilar argumento
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if ctx.proposal_collected and not ctx.argument_collected:
                # Verificar si el mensaje actual es un argumento
                es_argumento = (
                    has_argument_text(data.mensaje) or 
                    len(_normalize_text(data.mensaje)) >= 20
                )
                
                if es_argumento:
                    # Guardar argumento y avanzar a pedir contacto
                    conv_ref.update({
                        "argument_collected": True,
                        "contact_requested": True,
                        "contact_intent": "propuesta"
                    })
                    
                    # Construir lista de datos faltantes
                    missing = ctx.get_missing_contact_fields()
                    if not ctx.project_location:
                        missing.append("project_location")
                    
                    if missing:
                        if missing == ["project_location"]:
                            texto = build_project_location_request()
                        else:
                            texto = build_contact_request(missing)
                    else:
                        # Ya tiene todo
                        texto = "Perfecto, con estos datos escalamos tu propuesta."
                    
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
                else:
                    # Pedir argumento de nuevo
                    texto = craft_argument_question(
                        ctx.contact_info.get("nombre"),
                        ctx.project_location
                    )
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # FASE 3: Recopilar contacto
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if ctx.argument_collected and ctx.contact_requested:
                # Verificar quÃ© falta
                missing = ctx.get_missing_contact_fields()
                if not ctx.project_location:
                    missing.append("project_location")
                
                if missing:
                    if missing == ["project_location"]:
                        texto = build_project_location_request()
                    else:
                        texto = build_contact_request(missing)
                    
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
                else:
                    # Todo completo
                    nombre_txt = ctx.contact_info.get("nombre", "")
                    texto = (f"Gracias, {nombre_txt}. " if nombre_txt else "Gracias. ")
                    texto += "Con estos datos escalamos el caso y te contamos avances."
                    
                    append_mensajes(conv_ref, [
                        {"role": "user", "content": data.mensaje},
                        {"role": "assistant", "content": texto}
                    ])
                    return {"respuesta": texto, "fuentes": [], "chat_id": chat_id}
        
        # CAPA 4: RAG
        query_for_search = data.mensaje
        if ctx.has_reference:
            query_for_search = reformulate_query_with_context(data.mensaje, ctx.historial)
        
        hits = rag_search(query_for_search, top_k=5)

        # ğŸ› DEBUG: Ver scores de RAG
        print(f"\n{'='*60}")
        print(f"[RAG DEBUG] Query: '{query_for_search}'")
        print(f"[RAG DEBUG] Hits encontrados: {len(hits)}")
        for i, hit in enumerate(hits[:3], 1):
            print(f"  Hit {i}: score={hit.get('score', 0):.3f} | texto='{hit.get('texto', '')[:80]}...'")
        print(f"{'='*60}\n")
        
        # âœ… Validar RAG
        # âœ… Validar RAG
        if not validate_rag_relevance(hits):
            # Intento de respuesta genÃ©rica basada en el tema
            if any(kw in _normalize_text(data.mensaje) for kw in ["ley", "proyecto", "educacion", "educaciÃ³n"]):
                texto = (
                    "No encontrÃ© informaciÃ³n especÃ­fica sobre eso en mi base de datos actual. "
                    "Te recomiendo contactar directamente a la oficina de Wilder para informaciÃ³n mÃ¡s detallada."
                )
            else:
                texto = "No tengo informaciÃ³n especÃ­fica sobre eso en este momento. Â¿Hay algo mÃ¡s en lo que pueda ayudarte?"
        else:
            texto = layer4_generate_response_with_memory(ctx, clasificacion, hits)
        
        append_mensajes(conv_ref, [
            {"role": "user", "content": data.mensaje},
            {"role": "assistant", "content": texto}
        ])
        
        return {"respuesta": texto, "fuentes": hits, "chat_id": chat_id}
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"error": str(e)}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASIFICACIÃ“N COMPLETA (CONSULTAS Y PROPUESTAS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/clasificar")
async def clasificar(body: ClasificarIn):
    """
    Clasifica la conversaciÃ³n y guarda categorÃ­as.
    Maneja CONSULTAS y PROPUESTAS de forma inteligente.
    """
    try:
        chat_id = body.chat_id
        conv_ref = db.collection("conversaciones").document(chat_id)
        snap = conv_ref.get()
        
        if not snap.exists:
            return {"ok": False, "mensaje": "ConversaciÃ³n no encontrada"}
        
        conv_data = snap.to_dict() or {}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 1: Obtener el Ãºltimo mensaje del usuario
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        mensajes = conv_data.get("mensajes", [])
        ultimo_usuario = ""
        
        # Buscar el Ãºltimo mensaje del usuario (de atrÃ¡s hacia adelante)
        for m in reversed(mensajes):
            if m.get("role") == "user":
                ultimo_usuario = m.get("content", "")
                break
        
        if not ultimo_usuario:
            return {"ok": False, "mensaje": "No hay mensajes para clasificar"}
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 2: Detectar si es CONSULTA o PROPUESTA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Â¿Tiene propuesta guardada?
        propuesta = conv_data.get("current_proposal") or ""
        
        # Clasificar segÃºn el contexto
        if propuesta:
            # HAY PROPUESTA â†’ Clasificar como propuesta
            tipo = "propuesta"
            texto_a_clasificar = propuesta
        else:
            # NO HAY PROPUESTA â†’ PodrÃ­a ser consulta
            # Verificar si parece consulta
            es_consulta_heuristica = (
                ("?" in ultimo_usuario) or
                any(kw in _normalize_text(ultimo_usuario) 
                    for kw in ["que", "quÃ©", "como", "cÃ³mo", "cuando", "cuÃ¡ndo", 
                              "donde", "dÃ³nde", "wilder", "ley", "proyecto"])
            )
            
            if es_consulta_heuristica:
                tipo = "consulta"
                texto_a_clasificar = ultimo_usuario
            else:
                # No es consulta ni tiene propuesta â†’ skip
                return {"ok": True, "skipped": True, "reason": "ni_consulta_ni_propuesta"}
        
        print(f"[CLASIFICAR] Tipo detectado: {tipo}")
        print(f"[CLASIFICAR] Texto: {texto_a_clasificar[:100]}...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 3: Clasificar con LLM segÃºn el tipo
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        if tipo == "consulta":
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # CLASIFICAR CONSULTA
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            sys = (
                "Clasifica esta CONSULTA ciudadana.\n"
                "Devuelve SOLO JSON con:\n"
                "{\n"
                "  \"categoria_general\": \"Consulta\",\n"
                "  \"titulo_propuesta\": \"[Tema de la consulta en 5-8 palabras]\",\n"
                "  \"tono_detectado\": \"neutral\"\n"
                "}\n\n"
                "Ejemplos de tÃ­tulos:\n"
                "- 'Ley 2420 educaciÃ³n pospandemia'\n"
                "- 'Proyectos salud adultos mayores'\n"
                "- 'PosiciÃ³n movilidad sostenible'\n"
            )
            usr = f"Consulta del ciudadano:\n{texto_a_clasificar}"
            
        else:  # tipo == "propuesta"
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # CLASIFICAR PROPUESTA
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            ubicacion = conv_data.get("project_location") or ""
            
            sys = (
                "Clasifica esta PROPUESTA ciudadana.\n"
                "Devuelve SOLO JSON con:\n"
                "{\n"
                "  \"categoria_general\": \"[Infraestructura Urbana|Seguridad|Movilidad|EducaciÃ³n|Salud|Vivienda|Empleo|Medio Ambiente]\",\n"
                "  \"titulo_propuesta\": \"[AcciÃ³n + QuÃ© + DÃ³nde en mÃ¡x 60 chars]\",\n"
                "  \"tono_detectado\": \"propositivo\"\n"
                "}\n\n"
                "Reglas para el tÃ­tulo:\n"
                "- Comenzar con verbo (Mejorar, Construir, Arreglar, Instalar)\n"
                "- Incluir el QUÃ‰ (alumbrado, parque, vÃ­a)\n"
                "- Incluir el DÃ“NDE si existe\n"
                "- MÃ¡ximo 60 caracteres\n\n"
                "Ejemplos:\n"
                "- 'Mejorar alumbrado pÃºblico en Laureles'\n"
                "- 'Construir parque infantil en Aranjuez'\n"
                "- 'Reparar vÃ­as barrio Popular'\n"
            )
            
            if ubicacion:
                usr = f"Propuesta: {texto_a_clasificar}\nUbicaciÃ³n: {ubicacion}"
            else:
                usr = f"Propuesta: {texto_a_clasificar}"
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 4: Llamar al LLM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            out = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": sys},
                    {"role": "user", "content": usr}
                ],
                temperature=0.2,
                max_tokens=150
            ).choices[0].message.content.strip()
            
            # Limpiar respuesta (a veces el LLM devuelve ```json ... ```)
            out = out.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(out)
            
        except Exception as e:
            print(f"[CLASIFICAR] Error LLM: {e}")
            # Fallback bÃ¡sico
            if tipo == "consulta":
                data = {
                    "categoria_general": "Consulta",
                    "titulo_propuesta": "Consulta ciudadana",
                    "tono_detectado": "neutral"
                }
            else:
                data = {
                    "categoria_general": "General",
                    "titulo_propuesta": "Propuesta ciudadana",
                    "tono_detectado": "propositivo"
                }
        
        # Extraer datos
        categoria = data.get("categoria_general", "General")
        titulo = data.get("titulo_propuesta", "Sin tÃ­tulo")
        tono = data.get("tono_detectado", "neutral")
        
        print(f"[CLASIFICAR] CategorÃ­a: {categoria}")
        print(f"[CLASIFICAR] TÃ­tulo: {titulo}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 5: Guardar en Firestore (ACUMULATIVO)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        # Obtener categorÃ­as existentes
        categorias_existentes = conv_data.get("categoria_general") or []
        titulos_existentes = conv_data.get("titulo_propuesta") or []
        
        # Convertir a lista si es string (por compatibilidad)
        if isinstance(categorias_existentes, str):
            categorias_existentes = [categorias_existentes]
        if isinstance(titulos_existentes, str):
            titulos_existentes = [titulos_existentes]
        
        # Agregar nueva categorÃ­a si no existe
        if categoria not in categorias_existentes:
            categorias_existentes.append(categoria)
        
        # Agregar nuevo tÃ­tulo si no existe
        titulo_normalizado = _normalize_text(titulo)
        titulos_normalizados_existentes = [_normalize_text(t) for t in titulos_existentes]
        
        if titulo_normalizado not in titulos_normalizados_existentes:
            titulos_existentes.append(titulo)
        
        # Actualizar en BD
        conv_ref.update({
            "categoria_general": categorias_existentes,
            "titulo_propuesta": titulos_existentes,
            "tono_detectado": tono,
            "ultima_fecha": firestore.SERVER_TIMESTAMP
        })
        
        print(f"[CLASIFICAR] âœ… Guardado: {categorias_existentes} / {titulos_existentes}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 6: Retornar resultado
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        return {
            "ok": True,
            "clasificacion": {
                "tipo": tipo,  # 'consulta' o 'propuesta'
                "categoria_general": categoria,
                "titulo_propuesta": titulo,
                "tono_detectado": tono,
                "todas_categorias": categorias_existentes,  # Para el front
                "todos_titulos": titulos_existentes  # Para el front
            }
        }
        
    except Exception as e:
        print(f"[CLASIFICAR] âŒ Error fatal: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=10000)